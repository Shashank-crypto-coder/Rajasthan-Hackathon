{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement**\n",
        "* The problem statement that we have selected is to develop an ML model which gives us the duration of objects in a given video.\n",
        "* The steps included are :\n",
        "  * Conversion of video into frames\n",
        "  * Finding out the duration of the video\n",
        "  * Calculating the duration of each frame\n",
        "  * Applying object detection on each frame using YOLO algorithm\n",
        "  * Finding out unique objects present in the video\n",
        "  * Calculating the no.of.frames for each object in which the particular object is present\n",
        "  * Calculating the total duration of each detected object in the video "
      ],
      "metadata": {
        "id": "oVA2pt0ASCb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary libraries\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "6TNw75E-R-70"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conversion of video into frames"
      ],
      "metadata": {
        "id": "q0ccnMdNWAwc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "yn2Z0k5TvbJl"
      },
      "outputs": [],
      "source": [
        "#video to frames\n",
        "import cv2\n",
        "cap=cv2.VideoCapture(\"train-6074.mp4\")\n",
        "res,vf=cap.read()\n",
        "frames=[]\n",
        "count=0\n",
        "while res==True:\n",
        "  cv2.imwrite(\"frame%d.jpg\" %count,vf)\n",
        "  frames.append(cv2.resize(vf, (200, 500)))\n",
        "  res,vf=cap.read()\n",
        "  \n",
        "  count+=1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_frames=len(frames)\n",
        "print(\"No.of Frames in the given video : \", no_of_frames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMHeYdP7wKQv",
        "outputId": "9af84c0c-bda5-45b9-c85e-1385df80ae2e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No.of Frames in the given video :  133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding out the duration of the video"
      ],
      "metadata": {
        "id": "u2E7-M-IWFma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import json\n",
        "input_filename = \"SrisailamDam_Trim.mp4\"\n",
        "out = subprocess.check_output([\"ffprobe\", \"-v\", \"quiet\", \"-show_format\", \"-print_format\", \"json\", input_filename])\n",
        "ffprobe_data = json.loads(out)\n",
        "duration_seconds = float(ffprobe_data[\"format\"][\"duration\"])\n",
        "print(\"Duration of input Video : \",duration_seconds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhj5_9CDxCKf",
        "outputId": "917c75d5-48da-463e-f1c7-61a4246fcb85"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration of input Video :  4.074646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the duration of each frame"
      ],
      "metadata": {
        "id": "taASNN82WJTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Duration of each frame : \",duration_seconds/no_of_frames)\n",
        "duration_of_frame=duration_seconds/no_of_frames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEs_Pf1AxoDe",
        "outputId": "1d01f4ec-d175-4c76-8972-4713916e7fbf"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration of each frame :  0.030636436090225566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((frames[0].shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wwB9lo_5DSv",
        "outputId": "eaaa884f-c379-4d53-b387-ec446dc78074"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 200, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying object detection on each frame using YOLO algorithm"
      ],
      "metadata": {
        "id": "TntEVAZEWONJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "Ik_IzkAd0si7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net=cv2.dnn.readNetFromDarknet('/content/YOLOV3.cfg','/content/yolov3.weights')\n",
        "net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rarfS82k6wNK",
        "outputId": "708a2a29-663d-4720-aeb8-f3d4e52940a9"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "< cv2.dnn.Net 0x7f48a8885b70>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes=[]\n",
        "with open('/content/coco.names.txt','r') as f:\n",
        "  classes = [i.strip() for i in f.readlines()]"
      ],
      "metadata": {
        "id": "wdAi-odKINwB"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_objects(frame, net):\n",
        "    #read the image as BGR\n",
        "    my_img = cv2.resize(frame, (200,500)) # Change the input image size\n",
        "    # cv2_imshow(my_img)\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(my_img, 1/255, (416, 416), (0, 0, 0), swapRB=True, crop=False)\n",
        "\n",
        "    net.setInput(blob)\n",
        "    last_layer = net.getUnconnectedOutLayersNames()\n",
        "    last_out = net.forward(last_layer)\n",
        "\n",
        "    ht, wt, _ = my_img.shape\n",
        "\n",
        "    boxes = []\n",
        "    v,u=[],[]\n",
        "    confidences = []\n",
        "    classes_id = []\n",
        "    for output in last_out:\n",
        "        for detection in output:\n",
        "            score = detection[5:]\n",
        "            class_id = np.argmax(score)\n",
        "            confidence = score[class_id]\n",
        "            if confidence > 0.3: # Lower the confidence threshold\n",
        "                center_x = int(detection[0] * wt)\n",
        "                center_y = int(detection[1] * ht)\n",
        "                w = int(detection[2] * wt)\n",
        "                h = int(detection[3] * ht)\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                classes_id.append(class_id)\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.4, 0.3) # Adjust the NMS parameters\n",
        "    font = cv2.FONT_HERSHEY_PLAIN\n",
        "    # print(indexes)\n",
        "    colors = np.random.uniform(0, 255, size=(len(boxes), 3))\n",
        "    labels = []\n",
        "    for i in indexes.flatten():\n",
        "        x, y, w, h = boxes[i]\n",
        "        label = str(classes[classes_id[i]])\n",
        "        confidence = str(round(confidences[i], 2))\n",
        "        labels.append(label)\n",
        "        color = colors[i]\n",
        "        cv2.rectangle(my_img, (x, y), (x + w, y + h), color, 2)\n",
        "        cv2.putText(my_img, label + \" \" + confidence, (x, y + 20), font, 2, (0, 0, 0), 2)\n",
        "        v.append(label)\n",
        "    u.append(list(set(v)))\n",
        "    # print(u)\n",
        "    return my_img,u\n",
        "\n"
      ],
      "metadata": {
        "id": "ixMyaYAN3c_z"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=frames[120]\n",
        "res,p=detect_objects(img,net)\n",
        "# cv2_imshow(res)\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yDUppmw4Ojs",
        "outputId": "bca93d0f-22b2-464b-fe9f-fbac3c5261d8"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['car']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding out unique objects present in the video"
      ],
      "metadata": {
        "id": "I6xFIVkCWbFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_in_frames=[]\n",
        "for i in range(no_of_frames):\n",
        "  img=frames[i]\n",
        "  res,p=detect_objects(img,net)\n",
        "  images_in_frames.append(p[0])\n",
        "print(images_in_frames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOOAgP-64V1B",
        "outputId": "3149d620-a6fc-4675-af60-a6567ab10e55"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['car', 'train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['car', 'train'], ['car', 'train'], ['car', 'train'], ['car', 'train'], ['car', 'train'], ['car', 'train'], ['car', 'train'], ['car', 'train'], ['car', 'train'], ['train'], ['train'], ['train'], ['train'], ['train'], ['car', 'train'], ['car', 'train'], ['car', 'train'], ['car'], ['car', 'bus'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car', 'truck'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car'], ['car']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=[]\n",
        "for i in images_in_frames:\n",
        "  for j in i:\n",
        "    z.append(j)\n",
        "print(\"No.of Unique Objects Detected in the video : \",set(z))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQhesLgUOL7e",
        "outputId": "201124dc-f1b7-460b-d0f3-aef420b8a035"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No.of Unique Objects Detected in the video :  {'bus', 'car', 'train', 'truck'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the no.of.frames for each object in which the particular object is present"
      ],
      "metadata": {
        "id": "Kpydvyw7Wh3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tn=c=b=tk=0\n",
        "for i in images_in_frames:\n",
        "  for j in i:\n",
        "    if j==\"bus\":\n",
        "      b+=1\n",
        "    if j==\"car\":\n",
        "      c+=1\n",
        "    if j==\"train\":\n",
        "      tn+=1\n",
        "    if j==\"truck\":\n",
        "      tk+=1\n",
        "print(f'No.of frames in which bus appears {b}')\n",
        "print(f'No.of frames in which car appears {c}')\n",
        "print(f'No.of frames in which train appears {tn}')\n",
        "print(f'No.of frames in which truck appears {tk}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToV1IZo_QGEv",
        "outputId": "aa7229ab-5593-477b-81ae-91b02981eaa8"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No.of frames in which bus appears 1\n",
            "No.of frames in which car appears 52\n",
            "No.of frames in which train appears 94\n",
            "No.of frames in which truck appears 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the total duration of each detected object in the video"
      ],
      "metadata": {
        "id": "ibyzag3OWlBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Bus appears for {b*duration_of_frame} secs')\n",
        "print(f'Car appears for {c*duration_of_frame} secs')\n",
        "print(f'Train appears for {tn*duration_of_frame} secs')\n",
        "print(f'Truck appears for {tk*duration_of_frame} secs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKYxfnWwROA1",
        "outputId": "ddece121-ddac-4003-ef04-40d5b95c4910"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bus appears for 0.030636436090225566 secs\n",
            "Car appears for 1.5930946766917295 secs\n",
            "Train appears for 2.879824992481203 secs\n",
            "Truck appears for 0.030636436090225566 secs\n"
          ]
        }
      ]
    }
  ]
}